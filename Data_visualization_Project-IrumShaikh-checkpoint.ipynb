{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "HB3shnGVt4ZD"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbs4\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mselenium\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "# the following libraries will be used for the tasks of our project\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Selenium WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "hh0VSe5vw0vX",
    "outputId": "8c4efe24-7328-481e-f209-de2e0165f591"
   },
   "outputs": [],
   "source": [
    "# load the CSV file\n",
    "csv_df = pd.read_csv('cancer2017.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kqoSCmMQ0FGZ",
    "outputId": "18b25d66-55c3-4765-e8f1-1e6d06154fbe"
   },
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "csv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check columns in DataFrame\n",
    "print(\"CSV DataFrame Columns:\", csv_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip leading and trailing spaces from column names in the DataFrame\n",
    "csv_df.columns = csv_df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan:\n",
    "# Reshape csv_df: We'll melt csv_df into a format where each row represents a state and one cancer type, making it possible to compare state-level data to national-level data from cancer_url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the csv_df DataFrame\n",
    "reshaped_csv_df = pd.melt(csv_df, id_vars=['State'], var_name='Cancer Type', value_name='Cancer Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the reshaped DataFrame to confirm it's in the desired format\n",
    "reshaped_csv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the 'Cancer Data' column to ensure all values are numeric\n",
    "reshaped_csv_df['Cancer Data'] = pd.to_numeric(reshaped_csv_df['Cancer Data'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values and handle them\n",
    "print(reshaped_csv_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The output shows that there are 63 missing values in the Cancer Data column, which indicates that some state-level data might be missing or improperly formatted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be Filling the missing values with the Mean or Median. This is because we believe the missing data can be approximated by the average value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill with the mean or median of the column\n",
    "reshaped_csv_df['Cancer Data'].fillna(reshaped_csv_df['Cancer Data'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reshaped_csv_df['Cancer Type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize the cancer type columns\n",
    "reshaped_csv_df['Cancer Type'] = reshaped_csv_df['Cancer Type'].str.strip().str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in the columns to identify what type of missing data is present\n",
    "for col in reshaped_csv_df.columns:\n",
    "    print(f\"{col}: {reshaped_csv_df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recheck the dataframe\n",
    "print(reshaped_csv_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the reshaped DataFrame to ensure everything is good\n",
    "print(reshaped_csv_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the change\n",
    "print(reshaped_csv_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check information about data types \n",
    "print(reshaped_csv_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check unique values in categorical variables\n",
    "print(\"Unique Cancer Types:\", reshaped_csv_df['Cancer Type'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates\n",
    "print(\"Number of duplicate rows:\", reshaped_csv_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a bar chart to visualize cancer data by estate\n",
    "\n",
    "state_data = reshaped_csv_df.groupby('State')['Cancer Data'].sum().sort_values()\n",
    "state_data.plot(kind='barh', figsize=(12, 8), color='skyblue')\n",
    "plt.title(\"Cancer Data by State\")\n",
    "plt.xlabel(\"Cancer Data\")\n",
    "plt.ylabel(\"State\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Create a line graph to visualize cancer data by state\n",
    "\n",
    "state_data = reshaped_csv_df.groupby('State')['Cancer Data'].sum().sort_values()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(state_data.index, state_data.values, marker='o')   # Line + markers\n",
    "plt.title(\"Cancer Data Trend by State\")\n",
    "plt.xlabel(\"State\")\n",
    "plt.ylabel(\"Cancer Data\")\n",
    "plt.xticks(rotation=90)    # rotate names for clear view\n",
    "plt.grid(True)             # adds guiding grid for better readability\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution by cancer \n",
    "\n",
    "cancer_type_data = reshaped_csv_df.groupby('Cancer Type')['Cancer Data'].sum().sort_values()\n",
    "cancer_type_data.plot(kind='bar', figsize=(12, 6), color='blue')\n",
    "plt.title(\" Cancer Data by Cancer Type\")\n",
    "plt.xlabel(\"Cancer Type\")\n",
    "plt.ylabel(\"Cancer Data\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "correlation = reshaped_csv_df[['Cancer Data', ]].corr()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(data=reshaped_csv_df, x='Cancer Type', y='Cancer Data')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Spread of Cancer Cases by Cancer Type')\n",
    "plt.xlabel('Cancer Type')\n",
    "plt.ylabel('Cancer Cases')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=reshaped_csv_df, y='Cancer Type', x='Cancer Data')\n",
    "plt.title('Spread of Cancer Cases by Cancer Type')\n",
    "plt.xlabel('Cancer Cases')\n",
    "plt.ylabel('Cancer Type')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(reshaped_csv_df['Cancer Type'], reshaped_csv_df['Cancer Data'], color='skyblue')\n",
    "\n",
    "plt.xlabel('Cancer Type')\n",
    "plt.ylabel('Cancer Cases')\n",
    "plt.title('Cancer Cases Across Different Types')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate Cancer Data by Cancer Type\n",
    "cancer_trends = reshaped_csv_df.groupby('Cancer Type')['Cancer Data'].sum()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(cancer_trends.index, cancer_trends.values, marker='o', linestyle='-', color='green', label='All Cases')\n",
    "\n",
    "plt.xlabel('Cancer Type')\n",
    "plt.ylabel('Total Cancer Cases')\n",
    "plt.title('Total Cancer Cases by Cancer Type')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Group and sort data\n",
    "state_data = reshaped_csv_df.groupby('State')['Cancer Data'].sum().sort_values()\n",
    "\n",
    "# 3D Plot\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Create x-axis positions for states\n",
    "x = range(len(state_data))\n",
    "y = state_data.values\n",
    "z = [0] * len(state_data)  # base height = 0\n",
    "\n",
    "ax.plot(x, y, zs=0, zdir='z', marker='o')  # Draw 3D line\n",
    "\n",
    "# Labels\n",
    "ax.set_title(\"3D Line Chart - Cancer Data by State\")\n",
    "ax.set_xlabel(\"State Index\")\n",
    "ax.set_ylabel(\"Cancer Data\")\n",
    "ax.set_zlabel(\"Depth\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the CSV file\n",
    "csv_df = pd.read_csv('cancer2017.csv', encoding='ISO-8859-1')\n",
    "\n",
    "csv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace † with 0\n",
    "csv_df = csv_df.replace('†', '0')\n",
    "\n",
    "# Remove commas and any non-digit characters, then convert to int\n",
    "for col in csv_df.columns[1:]:\n",
    "    # Remove commas, spaces, and non-digit characters\n",
    "    csv_df[col] = csv_df[col].astype(str).str.replace(r'[^\\d]', '', regex=True)\n",
    "    # Convert empty strings to 0\n",
    "    csv_df[col] = csv_df[col].replace('', '0')\n",
    "    csv_df[col] = csv_df[col].astype(int)\n",
    "\n",
    "csv_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "value = reshaped_csv_df['Cancer Data'].sum()  # total cancer count\n",
    "max_value = value * 1.2  # Gauge upper bound (20% buffer)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "# Convert value to angle (0 to π)\n",
    "angle = (value / max_value) * np.pi\n",
    "\n",
    "# Gauge background arc\n",
    "theta = np.linspace(0, np.pi, 100)\n",
    "r = np.ones(100)\n",
    "ax.plot(theta, r, linewidth=30, alpha=0.3)\n",
    "\n",
    "# Value pointer\n",
    "ax.plot([0, angle], [0, 1], linewidth=4)\n",
    "\n",
    "# Display text\n",
    "ax.text(np.pi/2, 1.2, \"Cancer Data Gauge\", ha='center', fontsize=16)\n",
    "ax.text(angle, 1.05, f\"{value}\", fontsize=14, fontweight='bold')\n",
    "\n",
    "# Format gauge display\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_ylim(0, 1.2)\n",
    "ax.set_theta_zero_location(\"W\")\n",
    "ax.set_theta_direction(-1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "total_by_type = csv_df.drop(columns=['State']).sum().sort_values(ascending=False)\n",
    "top5_types = total_by_type.head(5).index  # Top 5 cancer types\n",
    "\n",
    "line_data = csv_df[['State'] + list(top5_types)]\n",
    "line_data.set_index('State', inplace=True)\n",
    "\n",
    "# ---------------- Create subplots ----------------\n",
    "fig, axs = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "# ---- Left: Line Plot (trends by state) ----\n",
    "for cancer in top5_types:\n",
    "    axs[0].plot(line_data.index, line_data[cancer], marker='o', linestyle='-', label=cancer)\n",
    "\n",
    "axs[0].set_xlabel('State')\n",
    "axs[0].set_ylabel('Number of Cases')\n",
    "axs[0].set_title('Top 5 Cancer Types Across States')\n",
    "axs[0].tick_params(axis='x', rotation=90)\n",
    "axs[0].legend()\n",
    "\n",
    "# ---- Right: Bar Plot (total cases by type) ----\n",
    "axs[1].bar(total_by_type.index, total_by_type.values, color='lightcoral')\n",
    "axs[1].set_xlabel('Cancer Type')\n",
    "axs[1].set_ylabel('Total Cases')\n",
    "axs[1].set_title('Total Cancer Cases by Type')\n",
    "axs[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the second step of the project. We are going to use the scrapping method from this page: https://synapse.koreamed.org/articles/1154445"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Scrape Cancer.org data\u001b[39;00m\n\u001b[32m      2\u001b[39m web_url = \u001b[33m\"\u001b[39m\u001b[33mhttps://synapse.koreamed.org/articles/1154445\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m response = \u001b[43mrequests\u001b[49m.get(web_url)\n",
      "\u001b[31mNameError\u001b[39m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "# Scrape Cancer.org data\n",
    "web_url = \"https://synapse.koreamed.org/articles/1154445\"\n",
    "response = requests.get(web_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.raise_for_status()  # Raise an exception for bad status codes\n",
    "html_content = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "tables = soup.find_all('table')\n",
    "print(f\"Number of tables found: {len(tables)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each table and extract data\n",
    "all_tables_data = []  # List to store all tables' data\n",
    "\n",
    "for table_index, table in enumerate(tables):\n",
    "    print(f\"\\nProcessing Table {table_index + 1}\")\n",
    "    \n",
    "    # Extract rows\n",
    "    rows = table.find_all('tr')\n",
    "    table_data = []\n",
    "    \n",
    "    for row in rows:\n",
    "        # Extract cells (both header and data cells)\n",
    "        cells = row.find_all(['td', 'th'])\n",
    "        cell_data = [cell.get_text(strip=True) for cell in cells]\n",
    "        table_data.append(cell_data)\n",
    "    \n",
    "    # Convert to a pandas DataFrame for better usability\n",
    "    df = pd.DataFrame(table_data)\n",
    "    print(df)  # Display the DataFrame (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nInitial Data:\")\n",
    "print(df.head())  # Display the raw table data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to read the table from the webpage\n",
    "tables = pd.read_html(web_url)\n",
    "\n",
    "# Display the first table\n",
    "df = tables[0]  # Assuming the table you want is the first one\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten multi-level columns\n",
    "df.columns = [' '.join(col).strip() for col in df.columns.values]\n",
    "\n",
    "# Display the updated column names\n",
    "print(\"Updated Columns:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove footnotes like \"a)\" or \"b)\" in column names\n",
    "df.columns = [col.replace(\"a)\", \"\").replace(\"b)\", \"\").strip() for col in df.columns]\n",
    "\n",
    "# Verify the cleaned column names\n",
    "print(\"Cleaned Columns After Footnote Removal:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\n",
    "    col.replace('Site/Type Site/Type', 'Site/Type')\n",
    "    .replace('New cases Both sexes', 'New cases - Both sexes')\n",
    "    .replace('New cases Men', 'New cases - Men')\n",
    "    .replace('New cases Women', 'New cases - Women')\n",
    "    .replace('Deaths Both sexes', 'Deaths - Both sexes')\n",
    "    .replace('Deaths Men', 'Deaths - Men')\n",
    "    .replace('Deaths Women', 'Deaths - Women')\n",
    "    .replace('Prevalent cases Both sexes', 'Prevalent cases - Both sexes')\n",
    "    .replace('Prevalent cases Men', 'Prevalent cases - Men')\n",
    "    .replace('Prevalent cases Women', 'Prevalent cases - Women')\n",
    "    for col in df.columns\n",
    "]\n",
    "\n",
    "# Display cleaned column names\n",
    "print(\"Cleaned Columns:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Data Overview:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for non-numeric values in the object columns\n",
    "def identify_non_numeric_values(df, columns):\n",
    "    non_numeric_entries = {}\n",
    "    \n",
    "    for col in columns:\n",
    "        # Try to convert the column to numeric values and check for any NaNs\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')  # Non-numeric will be NaN\n",
    "        non_numeric_entries[col] = df[col].isna().sum()  # Count how many NaNs (non-numeric entries) are present\n",
    "\n",
    "    return non_numeric_entries\n",
    "    \n",
    "# List of columns that should be numeric\n",
    "numeric_columns = [\n",
    "    'New cases - Men', 'New cases - Women',\n",
    "    'Deaths - Men', 'Deaths - Women',\n",
    "    'Prevalent cases - Men', 'Prevalent cases - Women'\n",
    "]\n",
    "\n",
    "# Identify non-numeric values in the specified columns\n",
    "non_numeric_values = identify_non_numeric_values(df, numeric_columns)\n",
    "\n",
    "# Print the non-numeric value counts\n",
    "print(\"Non-Numeric Value Counts:\")\n",
    "print(non_numeric_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to investigate non-numeric entries in the specified columns\n",
    "def investigate_non_numeric_entries(df, columns):\n",
    "    for col in columns:\n",
    "        # Check rows with NaN values (which were originally non-numeric)\n",
    "        non_numeric_rows = df[df[col].isna()]\n",
    "        print(f\"\\nNon-numeric entries in column '{col}':\")\n",
    "        print(non_numeric_rows[col])  # Print the non-numeric values\n",
    "\n",
    "# Investigate the non-numeric entries in the problematic columns\n",
    "investigate_non_numeric_entries(df, numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=numeric_columns)\n",
    "\n",
    "# Check the updated DataFrame\n",
    "print(df[numeric_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types after cleaning\n",
    "print(\"Data Types After Cleaning:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already parsed the HTML content with BeautifulSoup:\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "# Extract Table 2 (second table in the list)\n",
    "table_2 = tables[1]  # The second table is indexed as 1\n",
    "\n",
    "# Extract rows from Table 2\n",
    "rows_table_2 = table_2.find_all('tr')\n",
    "table_data_2 = []\n",
    "\n",
    "for row in rows_table_2:\n",
    "    cells = row.find_all(['td', 'th'])\n",
    "    cell_data = [cell.get_text(strip=True) for cell in cells]\n",
    "    table_data_2.append(cell_data)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_table_2 = pd.DataFrame(table_data_2)\n",
    "\n",
    "# Display the DataFrame for Table 2\n",
    "print(df_table_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the data is already loaded into df_table_2\n",
    "# Use the first row as column headers\n",
    "df_table_2.columns = df_table_2.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for clarity (optional)\n",
    "df_table_2.columns = [\n",
    "    \"Site_Type\",\n",
    "    \"Crude_Incidence_Both_Sexes\",\n",
    "    \"Crude_Incidence_Men\",\n",
    "    \"Crude_Incidence_Women\",\n",
    "    \"Age_Standardized_Both_Sexes\",\n",
    "    \"Age_Standardized_Men\",\n",
    "    \"Age_Standardized_Women\",\n",
    "]\n",
    "\n",
    "print(\"Cleaned DataFrame:\")\n",
    "print(df_table_2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing data\n",
    "print(\"Missing Data Overview for Table 2:\")\n",
    "print(df_table_2.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types for Table 2\n",
    "print(\"Data Types for Table 2:\")\n",
    "print(df_table_2.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numeric columns\n",
    "numeric_columns = [\n",
    "    \"Crude_Incidence_Both_Sexes\",\n",
    "    \"Crude_Incidence_Men\",\n",
    "    \"Crude_Incidence_Women\",\n",
    "    \"Age_Standardized_Both_Sexes\",\n",
    "    \"Age_Standardized_Men\",\n",
    "    \"Age_Standardized_Women\",\n",
    "]\n",
    "\n",
    "# Convert numeric columns to float, coercing errors to NaN\n",
    "df_table_2[numeric_columns] = df_table_2[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Check the data types after conversion\n",
    "print(\"Data Types After Conversion:\")\n",
    "print(df_table_2.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "df_table_2.dropna(subset=[\"Age_Standardized_Women\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Data Overview After Cleaning:\")\n",
    "print(df_table_2.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "print(\"Data Types After Cleaning:\")\n",
    "print(df_table_2.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display rows with missing values in 'Crude_Incidence_Men' or 'Age_Standardized_Men'\n",
    "missing_rows = df_table_2[df_table_2[['Crude_Incidence_Men', 'Age_Standardized_Men']].isnull().any(axis=1)]\n",
    "print(\"Rows with Missing Values:\")\n",
    "print(missing_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values in 'Crude_Incidence_Men' and 'Age_Standardized_Men' with 0\n",
    "df_table_2.loc[df_table_2['Site_Type'].isin(['Cervix uteri', 'Corpus uteri', 'Ovary']),\n",
    "               ['Crude_Incidence_Men', 'Age_Standardized_Men']] = 0\n",
    "\n",
    "# Verify the changes\n",
    "print(\"Rows After Fixing Missing Values:\")\n",
    "print(df_table_2[df_table_2['Site_Type'].isin(['Cervix uteri', 'Corpus uteri', 'Ovary'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Data Overview After Fix:\")\n",
    "print(df_table_2.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numeric columns\n",
    "print(\"Descriptive Statistics:\")\n",
    "print(df_table_2.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of unique site types\n",
    "print(\"\\nUnique Site Types:\")\n",
    "print(df_table_2['Site_Type'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align Column Names\n",
    "df.rename(columns={\"Site/Type\": \"Site_Type\"}, inplace=True)\n",
    "df_table_2.rename(columns={\"Site/Type\": \"Site_Type\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes \n",
    "merged_df = pd.concat([df, df_table_2, reshaped_csv_df], axis=1)\n",
    "print(\"Merged DataFrame shape:\", merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Data Overview:\")\n",
    "print(merged_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the row where 'Site_Type' is 'All sites'\n",
    "df = df[df[\"Site_Type\"] != \"All sites\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the second occurrence of 'Site_Type' (column index 10)\n",
    "merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]\n",
    "\n",
    "# Verify the cleaned DataFrame\n",
    "print(merged_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the type of the object\n",
    "print(type(merged_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = merged_df.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "print([col for col in numerical_columns if col not in merged_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"All sites\" row permanently\n",
    "merged_df = merged_df[merged_df['Site_Type'] != 'All sites']\n",
    "\n",
    "# Verify if the row is removed\n",
    "print(merged_df.head())  # Check the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Site_Type'] = merged_df['Site_Type'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.dropna(subset=['Site_Type', 'New cases - Both sexes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(merged_df['Site_Type'], merged_df['New cases - Both sexes'], color='skyblue')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Site Type')\n",
    "plt.ylabel('New Cases - Both Sexes')\n",
    "plt.title('New Cases for Both Sexes Across Different Site Types')\n",
    "\n",
    "# Rotate x-axis labels for readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacked Bar Chart: Deaths by Sex\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(merged_df['Site_Type'], merged_df['Deaths - Men'], color='blue', alpha=0.7, label='Men')\n",
    "plt.bar(merged_df['Site_Type'], merged_df['Deaths - Women'], color='pink', alpha=0.7, bottom=merged_df['Deaths - Men'], label='Women')\n",
    "\n",
    "plt.xlabel('Site Type')\n",
    "plt.ylabel('Number of Deaths')\n",
    "plt.title('Deaths by Site Type (Stacked for Men and Women)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot: Distribution of Prevalent Cases\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=merged_df[['Prevalent cases - Men', 'Prevalent cases - Women']], palette=['blue', 'pink'])\n",
    "\n",
    "plt.ylabel('Prevalent Cases')\n",
    "plt.title('Distribution of Prevalent Cases by Sex')\n",
    "plt.xticks(ticks=[0, 1], labels=['Men', 'Women'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line Plot: Age-Standardized Incidence Rate Trends\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(merged_df['Site_Type'], merged_df['Age_Standardized_Both_Sexes'], marker='o', linestyle='-', color='green', label='Both Sexes')\n",
    "plt.plot(merged_df['Site_Type'], merged_df['Age_Standardized_Men'], marker='o', linestyle='--', color='blue', label='Men')\n",
    "plt.plot(merged_df['Site_Type'], merged_df['Age_Standardized_Women'], marker='o', linestyle='--', color='pink', label='Women')\n",
    "\n",
    "plt.xlabel('Site Type')\n",
    "plt.ylabel('Age-Standardized Incidence Rate')\n",
    "plt.title('Age-Standardized Incidence Rate Trends')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie Chart: Distribution of Total Deaths by Sex\n",
    "plt.figure(figsize=(6, 6))\n",
    "total_deaths = [merged_df['Deaths - Men'].sum(), merged_df['Deaths - Women'].sum()]\n",
    "labels = ['Men', 'Women']\n",
    "colors = ['blue', 'pink']\n",
    "\n",
    "plt.pie(total_deaths, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140, shadow=True)\n",
    "plt.title('Proportion of Deaths by Sex')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute correlation matrix\n",
    "correlation_matrix = merged_df[numerical_columns].corr()\n",
    "\n",
    "# Create clustered heatmap\n",
    "sns.clustermap(\n",
    "    correlation_matrix,\n",
    "    annot=True,\n",
    "    cmap='coolwarm',\n",
    "    linewidths=0.5,\n",
    "    figsize=(8, 8)\n",
    ")\n",
    "\n",
    "plt.suptitle(\"Clustered Correlation Heatmap\", y=1.02, fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Chart: New Cases by Site Type (Men vs. Women)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(merged_df['Site_Type'], merged_df['New cases - Men'], color='blue', alpha=0.6, label='Men')\n",
    "plt.bar(merged_df['Site_Type'], merged_df['New cases - Women'], color='pink', alpha=0.6, label='Women')\n",
    "\n",
    "plt.xlabel('Site Type')\n",
    "plt.ylabel('New Cases')\n",
    "plt.title('New Cases by Site Type (Men vs. Women)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the merged dataset as a CSV file\n",
    "both_table_df.to_csv('both_table_df.csv', index=False)\n",
    "\n",
    "print(\"The new dataset has been saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
